{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import e\n",
    "from time import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "# from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.measure import shannon_entropy as Entropy\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### program arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir=\"E:/CMP/NN/project\"\n",
    "hingeDir=dir+\"/Gold_Hinge/FeaturesOutput/hinge_features.npy\"\n",
    "goldDir=dir+\"/Gold_Hinge/FeaturesOutput/cold_features.npy\"\n",
    "labelsDir=dir+\"/Gold_Hinge/FeaturesOutput/labels.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hinge=np.load(hingeDir)\n",
    "X_gold=np.load(goldDir)\n",
    "Y=np.load(labelsDir)['label']\n",
    "label_names=np.load(labelsDir)['label_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_answers.csv')\n",
    "icdar_classes = df['male'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx=label_names=='icdarTrainImages'\n",
    "# Y[idx]=icdar_classes[int(Y[idx])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, Y_train, Y_test = train_test_split(X_hinge, Y, test_size=0.2, random_state=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(np.concatenate((X_gold,X_hinge),axis=1), Y, test_size=0.2, random_state=1)\n",
    "# X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.25, random_state=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestParamsForSVM(X_train,Y_train,X_test,Y_test):\n",
    "    scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "    C = [ 0.01, 0.1, 1, 10, 100,1000]\n",
    "    gamma = [0.0001,0.001, 0.01, 0.1, 1,'scale']\n",
    "    kernel = ['linear','rbf']\n",
    "    scores = []\n",
    "    scores_train = []\n",
    "    \n",
    "    with open('svm_results0.csv','w') as csvfile:\n",
    "        np.savetxt(csvfile, [], delimiter=',',\n",
    "                   header='C,gamma,kernel,score_train,score')\n",
    "    for i in range(len(C)):\n",
    "        for j in range(len(gamma)):\n",
    "            for k in range(len(kernel)):\n",
    "                clf = SVC(C=C[i], gamma=gamma[j],kernel=kernel[k],class_weight='balanced')\n",
    "                clf.fit(scaler.transform( X_train), Y_train)\n",
    "                temp_train = clf.score(scaler.transform(X_train), Y_train)\n",
    "                print(\"Accuracy on training set: {:.2f}\".format(\n",
    "                    temp_train))    \n",
    "                scores_train.append((temp_train,i,j))\n",
    "                temp = clf.score(scaler.transform( X_test), Y_test)\n",
    "                print(\"Accuracy on test set: {:.4f}\".format(\n",
    "                    temp))\n",
    "                scores.append((temp,i,j))\n",
    "                with open('svm_results0.csv', 'a') as csvfile:\n",
    "                    np.savetxt(csvfile, np.array([[C[i],gamma[j],kernel[k],temp_train,temp]]), delimiter=',',fmt='%s')\n",
    "        \n",
    "    print(max(scores))\n",
    "    print(max(scores_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getBestParamsForSVM(X_train,Y_train,X_test,Y_test)\n",
    "# getBestParamsForSVM(X_train[:,np.arange(0,421)],Y_train,X_test[:,np.arange(0,421)],Y_test)\n",
    "# getBestParamsForSVM(X_train[:,np.arange(421,1200)],Y_train,X_test[:,np.arange(421,1200)],Y_test)\n",
    "# getBestParamsForANN(X_train,Y_train,X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.7397\n",
      "Accuracy on training set: 0.8897\n"
     ]
    }
   ],
   "source": [
    "# Classifier for gold features\n",
    "scaler = preprocessing.MinMaxScaler().fit(X_train[:,np.arange(0,421)])\n",
    "clf = SVC(C=1, gamma=0.001,kernel='linear',class_weight='balanced',random_state=1)\n",
    "X = scaler.transform(X_train[:,np.arange(0,421)])\n",
    "clf.fit(scaler.transform(X_train[:,np.arange(0,421)]), Y_train)\n",
    "score_test_gold = clf.score(scaler.transform( X_test[:,np.arange(0,421)]), Y_test)\n",
    "print(\"Accuracy on test set: {:.4f}\".format(\n",
    "    score_test_gold))\n",
    "score_train_gold = clf.score(scaler.transform( X_train[:,np.arange(0,421)]), Y_train)\n",
    "print(\"Accuracy on training set: {:.4f}\".format(\n",
    "    score_train_gold))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.8356\n",
      "Accuracy on training set: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Classifier for gold features\n",
    "scaler = preprocessing.MinMaxScaler().fit(X_train[:,np.arange(421,1200)])\n",
    "clf = SVC(C=10, gamma='scale',kernel='rbf',class_weight='balanced',random_state=1)\n",
    "clf.fit(scaler.transform(X_train[:,np.arange(421,1200)]), Y_train)\n",
    "score_test_hinge = clf.score(scaler.transform( X_test[:,np.arange(421,1200)]), Y_test)\n",
    "print(\"Accuracy on test set: {:.4f}\".format(\n",
    "    score_test_hinge))\n",
    "score_train_hinge = clf.score(scaler.transform( X_train[:,np.arange(421,1200)]), Y_train)\n",
    "print(\"Accuracy on training set: {:.4f}\".format(\n",
    "    score_train_hinge))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.8082\n",
      "Accuracy on training set: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# classifier for both\n",
    "scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "clf = SVC(C=10, gamma='scale',kernel='rbf',class_weight='balanced',random_state=1)\n",
    "clf.fit(scaler.transform(X_train), Y_train)\n",
    "score_test_hinge = clf.score(scaler.transform( X_test), Y_test)\n",
    "print(\"Accuracy on test set: {:.4f}\".format(\n",
    "    score_test_hinge))\n",
    "score_train_hinge = clf.score(scaler.transform( X_train), Y_train)\n",
    "print(\"Accuracy on training set: {:.4f}\".format(\n",
    "    score_train_hinge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]0.7945205479452054\n"
     ]
    }
   ],
   "source": [
    "cs = preprocessing.MinMaxScaler().fit(X_train)\n",
    "X_train = cs.transform(X_train) \n",
    "X_train = np.nan_to_num(X_train)\n",
    "\n",
    "X_test = cs.transform(X_test) \n",
    "X_test = np.nan_to_num(X_test)\n",
    "\n",
    "clf = SVC(kernel='rbf', verbose=True, C=10)\n",
    "clf.fit(X_train, Y_train)\n",
    "# print(clf.predict(X_test))\n",
    "print(clf.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][0.81081081 0.86486486 0.94594595 0.77777778 0.91666667 0.77777778\n",
      " 0.58333333 0.77777778 0.66666667 0.91666667]\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
     ]
    }
   ],
   "source": [
    "cs = preprocessing.MinMaxScaler()\n",
    "X = cs.fit_transform(X_hinge) \n",
    "X = np.nan_to_num(X)\n",
    "clf = SVC(kernel='rbf', verbose=True, C=10)\n",
    "scores = cross_val_score(clf, X, Y, cv=10)\n",
    "print(scores)\n",
    "y_pred_hinge = cross_val_predict(clf, X, Y, cv=10)\n",
    "# print(y_pred_hinge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][0.64864865 0.67567568 0.7027027  0.63888889 0.61111111 0.66666667\n",
      " 0.5        0.5        0.47222222 0.5       ]\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][0 1 0 0 1 0 1 1 1 0 0 1 1 1 0 0 0 0 0 1 0 0 1 1 0 0 1 0 1 1 1 1 1 0 0 1 0\n",
      " 0 1 0 1 1 0 0 1 1 1 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1\n",
      " 1 0 1 0 1 1 1 0 1 1 1 0 1 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 1 0\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1\n",
      " 0 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 1 1\n",
      " 0 0 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 1 1 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "cs = preprocessing.MinMaxScaler()\n",
    "X = cs.fit_transform(X_gold)\n",
    "X = np.nan_to_num(X)\n",
    "clf = SVC(kernel='rbf', verbose=True, C=10)\n",
    "scores = cross_val_score(clf, X, Y, cv=10)\n",
    "print(scores)\n",
    "y_pred_cold = cross_val_predict(clf, X, Y, cv=10)\n",
    "print(y_pred_cold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.maximum(y_pred_hinge, y_pred_cold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8044077134986226\n"
     ]
    }
   ],
   "source": [
    "print(sum(y_pred_hinge == Y) / float(len(Y)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "213524bb45a1aeaf737b1d8c77d7b8db5d425938d9dffc5f4bc6fe6dd3324700"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
