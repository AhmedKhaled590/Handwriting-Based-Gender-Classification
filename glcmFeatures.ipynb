{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from cmath import e\n",
    "from time import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.measure import shannon_entropy as Entropy\n",
    "from sklearn import preprocessing, svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from tuning import svmTuner\n",
    "import utils\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    extractGLCM(filename, outputFileName):\n",
    "    - filename: path to the image\n",
    "    - outputFileName: name of the output file\n",
    "    - returns: numpy array of features\n",
    "\"\"\"\n",
    "def extractGLCM(filename, outputFileName):\n",
    "    img = cv2.imread(filename)\n",
    "    \n",
    "    # Extract Gray Level Channel\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    step = [1]  # step size\n",
    "    step = np.asarray(step)\n",
    "    angle = [0, np.pi/4, np.pi/2, 3*np.pi/4]  # angles (0, 45, 90, 135)\n",
    "\n",
    "    coOccuranceMat = graycomatrix(\n",
    "        img, step, angle, levels=256, symmetric=True, normed=True)\n",
    "\n",
    "    # calculate the GLCM properties\n",
    "    contrast = graycoprops(coOccuranceMat, prop='contrast')\n",
    "    correlation = graycoprops(coOccuranceMat, prop='correlation')\n",
    "    energy = graycoprops(coOccuranceMat, prop='energy')\n",
    "    homogeneity = graycoprops(coOccuranceMat, prop='homogeneity')\n",
    "    # entropy = []\n",
    "    # entropy.insert(0, Entropy(coOccuranceMat[0, 0, :, :]))\n",
    "    # entropy.insert(1, Entropy(coOccuranceMat[0, 1, :, :]))\n",
    "    # entropy.insert(2, Entropy(coOccuranceMat[1, 0, :, :]))\n",
    "    # entropy.insert(3, Entropy(coOccuranceMat[1, 1, :, :]))\n",
    "    # entropy = np.array(entropy)\n",
    "\n",
    "    # calculate Entropy for each angle\n",
    "    \n",
    "    \n",
    "    # append all features to a numpy array\n",
    "    features = np.array([contrast.flatten(), homogeneity.flatten(),\n",
    "                        energy.flatten(), correlation.flatten()])\n",
    "\n",
    "    features = features.flatten()\n",
    "    features = features.reshape(1, -1)\n",
    "    \n",
    "\n",
    "    with open(outputFileName+'.csv', 'a') as csvfile:\n",
    "        np.savetxt(csvfile, features, fmt='%f', delimiter=',')\n",
    "        csvfile.close()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeFileIfExists(fileName):\n",
    "    if os.path.isfile(fileName):\n",
    "        os.remove(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeFeaturesToFile(features, fileName):\n",
    "    with open(fileName, 'a') as csvfile:\n",
    "        np.savetxt(csvfile, features, fmt='%f', delimiter=',')\n",
    "        csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeHeadersOfCSVFile(fileName):\n",
    "    with open(fileName, 'a') as csvfile:\n",
    "        np.savetxt(csvfile, [], delimiter=',',\n",
    "                   header='Contrast1,Contrast2,Contrast3,Contrast4,homogeneity1,homogeneity2,homogeneity3,homogeneity4,energy1,energy2,energy3,energy4,correlation1,correlation2,correlation3,correlation4,entropy1,entropy2,entropy3,entropy4')\n",
    "        csvfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFeaturesFromFile(fileName):\n",
    "    CSVData = open(fileName)\n",
    "    features = np.genfromtxt(CSVData, delimiter=\",\")\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeaturesFromFolder(folder,outputFileName,gender):\n",
    "    train_classes=[]\n",
    "    features=[]\n",
    "    for filename in os.listdir(folder):\n",
    "        try:\n",
    "            features.append(extractGLCM(folder+filename,outputFileName))\n",
    "            train_classes.append(gender)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "    return np.array(features),np.array(train_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractICDARFeatures():\n",
    "    features=[]\n",
    "    # read csv file\n",
    "    df = pd.read_csv('train_answers.csv')\n",
    "    # get the labels\n",
    "    icdar_classes = df['male'].values\n",
    "    print(icdar_classes.shape)\n",
    "    icdar_classes_train = np.array([])\n",
    "    i = 0\n",
    "    for filename in os.listdir('images_gender/images/train'):\n",
    "        try:\n",
    "            features.append(extractGLCM('images_gender/images/train/'+filename,'icdar'))\n",
    "            icdar_classes_train = np.append(icdar_classes_train, icdar_classes[i//2])\n",
    "            i = i + 1\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "    icdar_classes  = icdar_classes_train\n",
    "    return np.array(features),np.array(icdar_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestParamsForANN(X_train,Y_train,X_test,Y_test):\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    solver = ['adam', 'lbfgs', 'sgd']\n",
    "    alpha = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "    max_iter = [1000, 2000, 3000, 4000, 5000]\n",
    "    layer_sizes = [10,15,20,25,30,40]\n",
    "    scores = []\n",
    "    for i in range(len(solver)):\n",
    "        for j in range(len(alpha)):\n",
    "            for k in range(len(max_iter)):\n",
    "                for l in range(len(layer_sizes)):\n",
    "                    clf = MLPClassifier(solver=solver[i], alpha=alpha[j], max_iter=max_iter[k],\n",
    "                            hidden_layer_sizes=(layer_sizes[l],),random_state=1)\n",
    "                    clf.fit(scaler.transform(X_train), Y_train)\n",
    "                    print(\"Accuracy on training set: {:.2f}\".format(\n",
    "                        clf.score(scaler.transform(X_train), Y_train)))\n",
    "                    temp = clf.score(scaler.transform(X_test), Y_test)\n",
    "                    scores.append((temp,i,j,k,l))\n",
    "                    print(\"Accuracy on test set: {:.4f}\".format(\n",
    "                        temp))\n",
    "                    print(\"\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestParamsForSVM(X_train,Y_train,X_test,Y_test):\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    C = [10, 100, 1000,5000, 10000]\n",
    "    gamma = [.1, .01, .001, .0001, .00001]\n",
    "              \n",
    "    scores = []\n",
    "    for i in range(len(C)):\n",
    "        for j in range(len(gamma)):\n",
    "                clf = svm.SVC(C=C[i], gamma=gamma[j])\n",
    "                clf.fit(scaler.transform( X_train), Y_train)\n",
    "                print(\"Accuracy on training set: {:.2f}\".format(\n",
    "                    clf.score(scaler.transform( X_train), Y_train)))\n",
    "                temp = clf.score(scaler.transform( X_test), Y_test)\n",
    "                print(\"Accuracy on test set: {:.4f}\".format(\n",
    "                    temp))\n",
    "                scores.append(temp)\n",
    "                print(\"\\n\")\n",
    "    \n",
    "    print(\"Best score: {:.4f}\".format(max(scores))+ \" at index \" +str(scores.index(max(scores))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndPredict(X_train,Y_train,X_test,Y_test):\n",
    "    # train the classifier and predict the test data\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "    print(\"Training the classifier...\")          \n",
    "    clf = MLPClassifier( alpha= 0.1, hidden_layer_sizes= (20,) ,\n",
    "                       solver= 'adam',max_iter= 5000, random_state= 1) #65%\n",
    "\n",
    "    clf.fit(scaler.transform( X_train), Y_train) \n",
    "    \n",
    "    print(\"Predicting the test data...\")\n",
    "    score_training = clf.score(scaler.transform( X_train), Y_train) \n",
    "    score = clf.score(scaler.transform(X_test), Y_test)\n",
    "    print(\"Accuracy on test set: {:.4f}\".format(score))\n",
    "    print(\"Accuracy on training set: {:.4f}\".format(score_training))\n",
    "    \n",
    "    # clf = SVC(C=10.0, gamma=0.01)#62.3%\n",
    "    # clf = SVC(C=5000.0, class_weight='balanced', gamma=0.0001, kernel='rbf')#62.3%\n",
    "    \n",
    "# #     # clf = MLPClassifier( alpha= 0.01, hidden_layer_sizes= (15,) ,\n",
    "# #     #                    solver= 'adam',max_iter= 4000, random_state= 1) #61% without icdar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(282,)\n",
      "Training the classifier...\n",
      "Predicting the test data...\n",
      "Accuracy on test set: 0.6613\n",
      "Accuracy on training set: 0.6559\n"
     ]
    }
   ],
   "source": [
    "# removeFileIfExists('female.csv')\n",
    "# removeFileIfExists('male.csv')\n",
    "# removeFileIfExists('icdar.csv')\n",
    "\n",
    "# writeHeadersOfCSVFile('female.csv')\n",
    "# writeHeadersOfCSVFile('male.csv')\n",
    "# writeHeadersOfCSVFile('icdar.csv')\n",
    "\n",
    "# f_features,f_classes = extractFeaturesFromFolder('Females/Females/','female',0)\n",
    "# f_features =  f_features.reshape(f_features.shape[0], -1)\n",
    "# print(f_features.shape)\n",
    "# print(f_classes.shape)\n",
    "# m_features,m_classes = extractFeaturesFromFolder('Males/Males/','male',1)\n",
    "# m_features =  m_features.reshape(m_features.shape[0], -1)\n",
    "# print(m_features.shape)\n",
    "# print(m_classes.shape)\n",
    "# i_features,i_classes = extractICDARFeatures()\n",
    "# i_features = i_features.reshape(i_features.shape[0], -1)\n",
    "# print(i_features.shape)\n",
    "# print(i_classes.shape)\n",
    "\n",
    "f_features = readFeaturesFromFile('./female.csv')\n",
    "m_features = readFeaturesFromFile('./male.csv')\n",
    "i_features = readFeaturesFromFile('./icdar.csv')\n",
    "\n",
    "train_classes = []\n",
    "# read csv file\n",
    "df = pd.read_csv('train_answers.csv')\n",
    "# get the labels\n",
    "icdar_classes = df['male'].values\n",
    "print(icdar_classes.shape)\n",
    "icdar_classes_train = np.array([])\n",
    "\n",
    "for i in range(1, 132):\n",
    "    try:\n",
    "        train_classes.append(0)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "for i in range(1, 233):\n",
    "    try:\n",
    "        train_classes.append(1)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "for i in range(0, 564):\n",
    "    try:\n",
    "        icdar_classes_train = np.append(icdar_classes_train, icdar_classes[i//2])\n",
    "        i = i + 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "icdar_classes = icdar_classes_train\n",
    "\n",
    "# train_classes = np.array(train_classes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train = np.concatenate((f_features,m_features,i_features ),axis=0)\n",
    "# Y_train = np.concatenate((f_classes,m_classes,i_classes),axis=0)\n",
    "Y_train = np.concatenate((train_classes,icdar_classes),axis=0)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_train, Y_train, test_size=0.2,random_state=1)\n",
    "\n",
    "# getBestParamsForANN(X_train,Y_train,X_test,Y_test)\n",
    "# getBestParamsForSVM(X_train,Y_train,X_test,Y_test)\n",
    "trainAndPredict(X_train,Y_train,X_test,Y_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "213524bb45a1aeaf737b1d8c77d7b8db5d425938d9dffc5f4bc6fe6dd3324700"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
