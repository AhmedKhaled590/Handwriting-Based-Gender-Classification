{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from cmath import e\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,cross_validate\n",
    "from time import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG STEPS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#REF https://www.intel.com/content/www/us/en/develop/documentation/ipp-dev-reference/top/volume-2-image-processing/computer-vision/feature-detection-functions/histogram-of-oriented-gradients-hog-descriptor.html\n",
    "* Implementation of the HOG descriptor algorithm is as follows:\n",
    "1. Divide the image into small connected regions called cells, and for each cell compute a histogram of gradient directions or edge orientations for the pixels within the cell.\n",
    "2. Discretize each cell into angular bins according to the gradient orientation.\n",
    "3. Each cell's pixel contributes weighted gradient to its corresponding angular bin.\n",
    "4. Groups of adjacent cells are considered as spatial regions called blocks. The grouping of cells into a block is the basis for grouping and normalization of histograms.\n",
    "5. Normalized group of histograms represents the block histogram. The set of these block histograms represents the descriptor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractHOG(filename, outputFileName):\n",
    "    # Loading the image\n",
    "    img = cv2.imread(filename).astype('uint8')\n",
    "    #REF https://learnopencv.com/handwritten-digits-classification-an-opencv-c-python-tutorial/\n",
    "    #  In most cases we will use the default value of these parameters:\n",
    "    #  derivAperture, winSigma, histogramNormType, L2HysThreshold, gammaCorrection and nlevels \n",
    "    derivAperture = 1\n",
    "    winSigma = -1.\n",
    "    histogramNormType = 0\n",
    "    L2HysThreshold = 0.2\n",
    "    gammaCorrection = 1\n",
    "    nlevels = 64\n",
    "    #-----------------------------------------------------\n",
    "    #REF https://www.intel.com/content/www/us/en/develop/documentation/ipp-dev-reference/top/volume-2-image-processing/computer-vision/feature-detection-functions/histogram-of-oriented-gradients-hog-descriptor.html\n",
    "    # According to [Dalal05] the recommended values for the HOG parameters are:\n",
    "    # 1D centered derivative mask [-1, 0, +1]\n",
    "    # Detection window size is 64x128\n",
    "    # Cell size is 8x8\n",
    "    # Block size is 16x16 (2x2 cells)\n",
    "    #-----------------------------------------------------\n",
    "    img=cv2.resize(img,(64,128))\n",
    "    winSize = (64, 128)\n",
    "    # The notion of blocks exist to tackle illumination variation.\n",
    "    # A large block size makes local changes less significant while a smaller block \n",
    "    # size weights local changes more.\n",
    "    # Typically blockSize is set to 2 x cellSize\n",
    "    blockSize = (16, 16)\n",
    "    # The blockStride determines the overlap between neighboring blocks\n",
    "    # and controls the degree of contrast normalization.\n",
    "    # Typically a blockStride is set to 50% of blockSize.\n",
    "    blockStride = (8, 8)\n",
    "    #The cellSize is chosen based on the scale of the features important to do the classification.\n",
    "    # A very small cellSize would blow up the size of the feature vector\n",
    "    #  and a very large one may not capture relevant information\n",
    "    cellSize = (8,8)\n",
    "    # nbins sets the number of bins in the histogram of gradients.\n",
    "    # The authors of the HOG paper had recommended a \n",
    "    # value of 9 to capture gradients between 0 and 180 degrees in 20 degrees increments\n",
    "    nbins = 9\n",
    "    # Typically gradients can have any orientation between 0 and 360 degrees. \n",
    "    # These gradients are referred to as “signed” gradients as opposed to “unsigned” \n",
    "    # gradients that drop the sign and take values between 0 and 180 degrees. \n",
    "    # In the original HOG paper, unsigned gradients were used for pedestrian detection. \n",
    "    # In my experiments,for this problem, signed gradients produced slightly better results.\n",
    "    signedGradient = True\n",
    "    #-----------------------------------------------------\n",
    "    hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,\n",
    "    cellSize,nbins,derivAperture,winSigma,histogramNormType\n",
    "    ,L2HysThreshold,gammaCorrection,nlevels, signedGradient)\n",
    "    # img = cv2.resize(img, (64,128))\n",
    "\n",
    "    # img\tMatrix of the type CV_8U containing an image where \n",
    "    # HOG features will be calculated descriptors\tMatrix of the type CV_32F\n",
    "    #----------------------------------------------------------\n",
    "    # CV_8U is unsigned 8bit/pixel - ie a pixel can have values 0-255, \n",
    "    # this is the normal range for most image and video formats\n",
    "    descriptor = hog.compute(img)\n",
    "    with open(outputFileName+'.csv', 'a') as csvfile:\n",
    "        np.savetxt(csvfile, [descriptor], fmt='%f', delimiter=',')\n",
    "        csvfile.close()\n",
    "    return descriptor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeFileIfExists(fileName):\n",
    "    if os.path.isfile(fileName):\n",
    "        os.remove(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeFeaturesToFile(features, fileName):\n",
    "    with open(fileName, 'a') as csvfile:\n",
    "        np.savetxt(csvfile, features, fmt='%f', delimiter=',')\n",
    "        csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFeaturesFromFile(fileName):\n",
    "    CSVData = open(fileName)\n",
    "    features = np.genfromtxt(CSVData, delimiter=\",\")\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeaturesFromFolder(folder,outputFileName,gender):\n",
    "    train_classes=[]\n",
    "    features=[]\n",
    "    for filename in os.listdir(folder):\n",
    "        try:\n",
    "            features.append(extractHOG(folder+filename,outputFileName))\n",
    "            train_classes.append(gender)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "    return np.array(features),np.array(train_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractICDARFeatures():\n",
    "    features=[]\n",
    "    # read csv file\n",
    "    df = pd.read_csv('train_answers.csv')\n",
    "    # get the labels\n",
    "    icdar_classes = df['male'].values\n",
    "    print(icdar_classes.shape)\n",
    "    icdar_classes_train = np.array([])\n",
    "    i = 0\n",
    "    for filename in os.listdir('images_gender/images/train'):\n",
    "        try:\n",
    "            features.append(extractHOG('images_gender/images/train/'+filename,'icdar_hog'))\n",
    "            icdar_classes_train = np.append(icdar_classes_train, icdar_classes[i//2])\n",
    "            i = i + 1\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "    icdar_classes  = icdar_classes_train\n",
    "    return np.array(features),np.array(icdar_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestParamsForSVM(X_train, Y_train, scalerOutputFileName='scaler.joblib'):\n",
    "    scaler = preprocessing.MinMaxScaler().fit(X_train)\n",
    "\n",
    "    GridSearchCV_parameters = {\n",
    "        'C': [0.01, 0.1, 1, 10, 100, 1000],\n",
    "        'gamma': [0.0001, 0.001, 0.01, 0.1, 1, 'scale'],\n",
    "        'kernel': ['rbf', 'linear']\n",
    "    }\n",
    "\n",
    "    t0 = time()\n",
    "    clf = GridSearchCV(SVC(class_weight='balanced'),\n",
    "                       GridSearchCV_parameters,  refit=True, cv=9)\n",
    "\n",
    "    clf = clf.fit(scaler.transform(X_train), Y_train)\n",
    "    print(\"Best estimator found by grid search:\")\n",
    "    print(\"\\nBest parameters: \", clf.best_params_)\n",
    "    print(\"Mean Cross Validation Score: %0.2f\" % clf.best_score_)\n",
    "    print(\"Training time: %.3f\" % (time() - t0))\n",
    "    return clf.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeaturesFromScratch():\n",
    "    removeFileIfExists('female_hog.csv')\n",
    "    removeFileIfExists('male_hog.csv')\n",
    "    removeFileIfExists('icdar_hog.csv')\n",
    "\n",
    "\n",
    "    f_features,f_classes = extractFeaturesFromFolder('Females/Females/','female_hog',0)\n",
    "    f_features =  f_features.reshape(f_features.shape[0], -1)\n",
    "    print(f_features.shape)\n",
    "    print(f_classes.shape)\n",
    "    m_features,m_classes = extractFeaturesFromFolder('Males/Males/','male_hog',1)\n",
    "    m_features =  m_features.reshape(m_features.shape[0], -1)\n",
    "    print(m_features.shape)\n",
    "    print(m_classes.shape)\n",
    "    i_features,i_classes = extractICDARFeatures()\n",
    "    i_features = i_features.reshape(i_features.shape[0], -1)\n",
    "    print(i_features.shape)\n",
    "    print(i_classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FeaturesFromScratch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(X_train,Y_train,X_test,Y_test):\n",
    "    # train the classifier and predict the test data\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    print(\"Training the classifier...\")          \n",
    "    clf = SVC(C=100.0, gamma=0.01,kernel='rbf',class_weight='balanced',random_state=1)\n",
    "    clf.fit(scaler.transform( X_train), Y_train) \n",
    "    \n",
    "    print(\"Predicting the test data...\")\n",
    "    # score_training = clf.score(scaler.transform( X_train), Y_train) \n",
    "    # score = clf.score(scaler.transform(X_test), Y_test)\n",
    "    predicted_labels = clf.predict(scaler.transform(X_test))\n",
    "    score = accuracy_score(Y_test, predicted_labels)\n",
    "    print(\"Accuracy on test set: {:.4f}\".format(score))\n",
    "    print(\"Accuracy on training set: {:.4f}\".format(clf.score(scaler.transform( X_train), Y_train)))\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232, 13572)\n",
      "(282,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# FeaturesFromScratch() \n",
    "f_features = readFeaturesFromFile('female_hog.csv')\n",
    "m_features = readFeaturesFromFile('male_hog.csv')\n",
    "i_features = readFeaturesFromFile('icdar_hog.csv')\n",
    "\n",
    "\n",
    "# f_features = np.delete(f_features,np.arange(13,17),1)\n",
    "# m_features = np.delete(m_features,np.arange(13,17),1)\n",
    "# i_features = np.delete(i_features,np.arange(13,17),1)\n",
    "\n",
    "# f_features = f_features[:,[0,4,8,12]]\n",
    "# m_features = m_features[:,[0,4,8,12]]\n",
    "# i_features = i_features[:,[0,4,8,12]]\n",
    "\n",
    "\n",
    "print(m_features.shape)\n",
    "\n",
    "train_classes = []\n",
    "# read csv file\n",
    "df = pd.read_csv('train_answers.csv')\n",
    "# get the labels\n",
    "icdar_classes = df['male'].values\n",
    "print(icdar_classes.shape)\n",
    "icdar_classes_train = np.array([])\n",
    "\n",
    "for i in range(1, 132):\n",
    "    try:\n",
    "        train_classes.append(0)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "for i in range(1, 233):\n",
    "    try:\n",
    "        train_classes.append(1)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "for i in range(0, 564):\n",
    "    try:\n",
    "        icdar_classes_train = np.append(icdar_classes_train, icdar_classes[i//2])\n",
    "        i = i + 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "icdar_classes = icdar_classes_train\n",
    "\n",
    "X_train = np.concatenate((f_features,m_features,i_features),axis=0)\n",
    "Y_train = np.concatenate((train_classes,icdar_classes),axis=0)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X_train, Y_train, test_size=.1)\n",
    "\n",
    "X_test, X_val, Y_test, Y_val = train_test_split(\n",
    "    X_test, Y_test, test_size=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svm = getBestParamsForSVM(X_train,Y_train)\n",
    "clf_svm.fit(X_train,Y_train)\n",
    "score = clf_svm.score(X_test,Y_test)\n",
    "score_train = clf_svm.score(X_train,Y_train)\n",
    "print(\"Accuracy on test set: {:.4f}\".format(score))\n",
    "print(\"Accuracy on training set: {:.4f}\".format(score_train))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c643d9f149e4249868a18915091ba67879cea58d4ea61b523066383dcc8e9746"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
